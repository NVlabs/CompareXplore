# SPDX-FileCopyrightText: Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from pytriton.client import FuturesModelClient
from model import Model, get_y_with_target
from config import FLAGS
from saver import saver
from utils import OurTimer, format_seconds


from tqdm import tqdm
import torch

from collections import OrderedDict
import numpy as np


class PytritonModel(Model):
    def __init__(self, init_pragma_dict=None, dataset=None, task=None):
        super(PytritonModel, self).__init__()
        self.task = FLAGS.task
        self.target_list = self._get_target_list()

        self.dummy_parameter = torch.nn.Linear(1, 1)

        # Following: try to not touch too much
        # Given by Robert and modified by Yunsheng:
        # Tip: Try below on scai3 which tends to be faster...

        # cd ~/software-gnn/file/pairwise_data
        # docker load -i rkirby-nemo-aligner.hls-rm.tar.gz

        # docker run --gpus all --rm=true --net host -it nvcr.io/nvidian/rkirby-nemo-aligner:hls-rm bash
        # python -u /opt/NeMo-Aligner/examples/nlp/gpt/serve_reward_model.py \
        #     --config-path=/opt/NeMo-Aligner/examples/nlp/gpt/conf/ \
        #     --config-name=inference_rm \
        #     trainer.num_nodes=1 \
        #     trainer.devices=$NUM_GPUS \
        #     rm_model_file=$CHECKPOINT_NEMO_FILE \
        #     inference.micro_batch_size=2 \
        #     inference.port=1234 \
        #     ++model.tensor_model_parallel_size=1 \
        #     trainer.precision=32

        self.host = 'localhost'
        self.port = '1234'
        self.model_name = 'reward_model'

        self.infer_time_li = []

    def forward(
        self, data, forward_pairwise, tvt=None, epoch=None, iter=None, test_name=None
    ):
        # total_loss = 0.0
        out_dict = OrderedDict()
        loss_dict = OrderedDict()

        mode = 'normal'
        self._decode(data, out_dict, loss_dict, mode)

        response_li = []
        with FuturesModelClient(
            f"{self.host}:{self.port}", self.model_name, max_workers=10
        ) as client:
            if forward_pairwise and FLAGS.pairwise_class:
                assert type(data.txt) is list and len(data.txt) == 1
                txt_li = data.txt[0]
                assert (
                    type(txt_li) is list and len(txt_li) % 2 == 0
                )  # first half: d1; second half: d2

                # saver.log_info(f'data.txt=\n{data.txt}\n{len(data)}\n{len(data[0])}')
                # exit()

                li_1, li_2 = self._split_li_into_2_halves(txt_li)

                for d_1, d_2 in zip(li_1, li_2):

                    # print(f"c['text']={c['text']}")
                    # print(f"r['text']={r['text']}")

                    c_to_use = d_1
                    r_to_use = d_2

                    # new_txt = "I'm giving you an HLS design for matrix multiplication, can you give me the reward?"
                    # c_to_use = f'{new_txt}\n{c_to_use}'
                    # r_to_use = f'{new_txt}\n{r_to_use}'

                    sentences = self.to_array([c_to_use, r_to_use])
                    # print(f"sentences={sentences}")
                    timer = OurTimer()
                    rewards = client.infer_batch(sentences=sentences).result()[
                        'rewards'
                    ]
                    self.infer_time_li.append(timer.time_and_clear(only_seconds=True))
                    # print(f"rewards={rewards}")
                    r1, r2 = rewards[0].item(), rewards[1].item()
                    if r1 >= r2:
                        # The code below is given by Robert in data_preprocessing.ipynb.
                        # His code uses csv data generated by pairwise.py;
                        # The question we are asking is whether design 1's perf is <= than design2,
                        # Check pairwise.py if unsure!
                        # i,e. whether design 1's layency is higher than design 2.
                        # Be super careful NOT to mess it up!
                        # def get_jsonl(dataframe):
                        #     jsonl = []
                        #     for _, entry in dataframe.iterrows():
                        #         prompt, answer = entry['prompt'], entry['answer']
                        #         prompt_lines = prompt.split('\n')
                        #         sample_a_start, sample_b_start, end = prompt_lines.index('#design 1:'), prompt_lines.index('#design 2:'), len(prompt_lines)
                        #         a = prompt_lines[sample_a_start+1:sample_b_start]
                        #         b = prompt_lines[sample_b_start+1:end-1]
                        #         if answer == 'Yes' :
                        #             chosen, rejected = a, b
                        #         else :
                        #             chosen, rejected = b, a
                        #         jsonl.append({
                        #             'text':"\n".join(chosen)
                        #         })
                        #         jsonl.append({
                        #             'text':"\n".join(rejected)
                        #         })
                        #     return jsonl
                        response_li.append('Yes')
                    else:
                        response_li.append('No')

                if len(self.infer_time_li) % 20 == 0:
                    avg_time = format_seconds(np.mean(self.infer_time_li))
                    saver.log_info_at_most(
                        f'Average pytriton infer time={avg_time}', f'infer_time_li', 10
                    )

                    # exit()
                mode = 'pairwise_class'
                self._decode(data, out_dict, loss_dict, mode, response_li)

        return out_dict, torch.tensor(0.0), loss_dict, torch.tensor(0.0)

    def _decode(self, data, out_dict, loss_dict, mode, response_li=None):
        for target_name in self.target_list:
            out = torch.zeros_like(get_y_with_target(data, 'perf'))
            if mode == 'normal':
                target_name_s = target_name
                out_dict[target_name_s] = out

            elif mode == 'pairwise_class':
                target_name_s = f'{target_name}_pairwise_class'
                assert (
                    type(response_li) is list and len(response_li) > 0
                ), f'response_li={response_li}'

                answer_li = (
                    []
                )  # tricky! for every target, we get the same reaponse (TODO: set target_list dynamically somehow to be efficient)
                for response in response_li:
                    # Below also tricky!
                    # 'yes' means that design 1's perf <= design 2's perf.
                    # When assigning ground-truth in pairwise.py
                    #   def _get_comp_result(e1, e2):
                    #       return 1 if e1 <= e2 else 0
                    # This means 1 --> [0, 1]
                    #            0 --> [1, 0]
                    if 'yes' in response.lower():
                        answer = [0, 1]
                    elif 'no' in response.lower():
                        answer = [1, 0]
                    else:
                        answer = [0, 1]
                    answer_li.append(answer)

                answer_mat = torch.tensor(answer_li)
                out_dict[target_name_s] = answer_mat
                # saver.log_info(f'answer_mat={answer_mat}')
                # exit()

            else:
                assert False

            loss_dict[target_name_s] = torch.tensor(0.0)

    def _split_li_into_2_halves(self, li):
        length = len(li)
        assert length % 2 == 0  # divisible by 2 -- otherwise data loader has some issue
        half_point = int(length / 2)
        d1 = li[0:half_point]
        d2 = li[half_point:]
        assert len(d1) == len(d2)
        return d1, d2

    def to_array(self, str_list: list[str]) -> np.ndarray:
        array = np.array(str_list)
        array = np.char.encode(array, "utf-8")
        array = np.expand_dims(array, -1)
        return array
